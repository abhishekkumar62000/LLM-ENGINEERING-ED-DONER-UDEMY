{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% ▕████████████████▏ 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% ▕████████████████▏ 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% ▕████████████████▏ 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% ▕████████████████▏   96 B                         \n",
      "pulling 34bb5ab01051... 100% ▕████████████████▏  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Some examples include:\n",
      "\n",
      "1. **Content Creation**: Generative AI can be used to generate high-quality content such as articles, social media posts, and product descriptions. This can save time and resources for content creators and help businesses maintain a consistent tone and style.\n",
      "\n",
      "2. **Marketing and Advertising**: Generative AI can be used to create personalized marketing messages, product recommendations, and ad copy. It can also help optimize ad targeting and improve conversion rates.\n",
      "\n",
      "3. **Product Design and Development**: Generative AI can be used to design new products, such as fashion items, furniture, or electronics. This can save time and resources for designers and engineers.\n",
      "\n",
      "4. **Customer Service**: Generative AI can be used to power chatbots and virtual assistants that provide customer support and answer frequently asked questions.\n",
      "\n",
      "5. **Data Analysis and Visualization**: Generative AI can be used to analyze and visualize large datasets, identifying patterns and trends that may not be visible to human analysts.\n",
      "\n",
      "6. **Predictive Maintenance**: Generative AI can be used to predict when equipment is likely to fail, allowing for proactive maintenance and reducing downtime.\n",
      "\n",
      "7. **Supply Chain Optimization**: Generative AI can be used to optimize supply chain operations, predicting demand and identifying the most efficient routes for shipments.\n",
      "\n",
      "8. **Financial Analysis**: Generative AI can be used to analyze financial data, identify trends, and make predictions about future market behavior.\n",
      "\n",
      "9. **Creative Collaboration**: Generative AI can be used to collaborate with human creatives on projects such as music composition, art generation, or scriptwriting.\n",
      "\n",
      "10. **Cybersecurity**: Generative AI can be used to detect and respond to cyber threats in real-time, identifying patterns and anomalies that may indicate a breach.\n",
      "\n",
      "11. **Human Resources**: Generative AI can be used to screen resumes, identify top candidates, and provide personalized job recommendations.\n",
      "\n",
      "12. **E-commerce**: Generative AI can be used to personalize product recommendations, optimize product listings, and improve customer engagement.\n",
      "\n",
      "13. **Healthcare**: Generative AI can be used to analyze medical images, diagnose diseases, and develop personalized treatment plans.\n",
      "\n",
      "14. **Education**: Generative AI can be used to create personalized learning experiences, generate educational content, and provide real-time feedback to students.\n",
      "\n",
      "15. **Architecture and Engineering**: Generative AI can be used to design buildings, bridges, and other infrastructure projects, optimizing for factors such as sustainability, cost, and functionality.\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative use cases emerge across various industries.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can help businesses save time and resources on content creation.\n",
      "2. **Image and Video Generation**: Generative AI can create realistic images and videos that can be used for various purposes such as marketing materials, product demos, or training simulations.\n",
      "3. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants to provide customer support, answer frequently asked questions, and help with transactions.\n",
      "4. **Product Design and Development**: Generative AI can assist in designing new products, such as furniture, clothing, or electronics, by generating 3D models, prototypes, and even functional designs.\n",
      "5. **Marketing Automation**: Generative AI can automate marketing tasks such as lead generation, email campaigns, and ad creation, helping businesses streamline their marketing processes.\n",
      "6. **Data Analysis and Visualization**: Generative AI can analyze large datasets and generate visualizations to help businesses gain insights into customer behavior, market trends, and operational performance.\n",
      "7. **Creative Writing and Editing**: Generative AI can assist writers with tasks such as suggesting alternative phrases, editing text, or even generating entire articles or stories.\n",
      "8. **Speech Synthesis and Voice Acting**: Generative AI can generate realistic speech sounds and voices that can be used for voice-overs, audiobooks, or even creating virtual characters.\n",
      "9. **Predictive Analytics and Forecasting**: Generative AI can analyze historical data and generate predictions about future trends, helping businesses make informed decisions about investments, production, and more.\n",
      "10. **Business Process Automation**: Generative AI can automate repetitive business processes such as document processing, invoice generation, or even account reconciliations.\n",
      "\n",
      "Some specific examples of businesses using Generative AI include:\n",
      "\n",
      "* **Amazon**: Uses generative AI to create personalized product recommendations for customers\n",
      "* **Microsoft**: Uses generative AI to generate custom product designs and prototypes\n",
      "* **Hertz**: Uses generative AI to create personalized car rental offers and experiences\n",
      "* **Google**: Uses generative AI to create realistic images of buildings, landscapes, and even entire cities\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: Autogenerated content such as product descriptions, social media posts, and articles can help reduce content creation costs and improve consistency.\n",
      "2. **Personalization**: Generative AI-powered algorithms can create personalized recommendations for customers based on their preferences and browsing history.\n",
      "3. **Marketing Automation**: Automated marketing campaigns can be generated using generative AI, allowing businesses to scale their marketing efforts more efficiently.\n",
      "4. **Virtual Product Design**: Generative AI can help designers create new product concepts, reducing the need for iterative design processes and improving innovation rates.\n",
      "5. **Chatbots and Virtual Assistants**: Generative AI-powered chatbots and virtual assistants can provide 24/7 customer support and improve customer engagement.\n",
      "6. **Data Augmentation**: Generative AI can generate additional data for use in machine learning models, helping businesses improve the accuracy of their predictive models.\n",
      "7. **Image Generation**: Generative AI can create photorealistic images for marketing materials, product packaging, or even virtual try-on scenarios.\n",
      "8. **Speech Synthesis**: Generative AI-powered speech synthesis tools can help reduce transcription costs and improve communication efficiency in industries such as healthcare and finance.\n",
      "9. **Music Composition**: Generative AI can compose original music tracks for advertising campaigns, videos, or video games.\n",
      "10. **Predictive Maintenance**: By analyzing equipment sensor data, generative AI models can predict maintenance needs, reducing downtime and improving overall operational efficiency.\n",
      "\n",
      "Some specific examples of businesses using generative AI include:\n",
      "\n",
      "* **Walmart**: Uses generative AI to automate content creation and improve marketing campaigns.\n",
      "* **Sephora**: Uses generative AI-powered chatbots to provide customer support and improve the shopping experience.\n",
      "* **Dior**: Uses generative AI to create personalized product recommendations for customers.\n",
      "* **American Airlines**: Uses generative AI to power its virtual assistant, enabling passengers to access flight information and book tickets online.\n",
      "\n",
      "These applications demonstrate the vast potential of Generative AI in transforming business processes and improving operational efficiency.\n"
     ]
    }
   ],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling aabd4debf0c8... 100% ▕████████████████▏ 1.1 GB                         \n",
      "pulling 369ca498f347... 100% ▕████████████████▏  387 B                         \n",
      "pulling 6e4c38e1172f... 100% ▕████████████████▏ 1.1 KB                         \n",
      "pulling f4d24e9138dd... 100% ▕████████████████▏  148 B                         \n",
      "pulling a85fe2a2e58e... 100% ▕████████████████▏  487 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so I'm trying to figure out the core concepts behind large language models (LLMs), specifically focusing on what a neural network is, attention, and what the transformer does. I remember hearing that LLMs are really good at understanding and generating human-like text, but I'm not exactly sure how they work under the hood.\n",
      "\n",
      "Starting with the definition of a neural network. From what I've studied before, a neural network is basically a set of algorithms designed to recognize patterns in data. It does this through connected layers of nodes where each node represents a value that's transformed as it moves from an input layer to an output layer, passing information on as it goes. The key here is understanding how these nodes process information and pass it on. Maybe the brain uses something similar for recognizing visual scenes or processing speech patterns?\n",
      "\n",
      "But wait, I think neural networks are made up of layers like the input layer, hidden layers, and an output layer. Each layer has nodes that receive inputs, apply weights, and sum them up to produce an output. These outputs then feed into the next layer. So in a LLM, perhaps multiple layers are used to process different aspects of the text or the user's query?\n",
      "\n",
      "The user mentioned attention and transformers. I've heard \"transformers\" before in the context of models like GPT-3. The word transformer suggests that it's based on transforming some form of data, maybe focusing on particular parts of the text. Transformers might be a neural network approach but structured differently. Instead of processing each layer one after another, they probably look at sequences more flexibly.\n",
      "\n",
      "Then there's attention. I think attention mechanisms allow models to focus on specific parts of the input as needed. In LLMs, when they translate user words into context or generate responses, attention must help them determine which word from a large vocabulary relates best to their query. It keeps the model flexible enough to adapt to different contexts and outputs.\n",
      "\n",
      "Putting it all together for a LLM: maybe each part of the model is like a separate neural network, focusing on specific subtasks or parts of speech. The 'attention' allows these networks to switch focus when needed, ensuring the model doesn't become too rigid. The term \"transformer\" might refer to the way each submodel processes input by treating it as sequences processed in parallel without strict layers.\n",
      "\n",
      "So for a LLM's neural network: It's divided into multiple components or models that are each specialized for different tasks. They work together with attention mechanisms to focus on relevant information, and perhaps use transformers where each model handles sequential data independently, enhancing flexibility.\n",
      "\n",
      "I'm still not super clear on the exact definitions though. I think neural networks in LLMs process sequences through layers with hidden states, while transformers break down the sequence into components that are processed differently without strict sequencing. Attention helps these models attend to specific parts during processing.\n",
      "\n",
      "To sum up, a neural network in an LLM is composed of several interconnected layers that transform and handle sequential data, often using attention mechanisms for context focusing. The transformer approach breaks this into parallel subtasks or models, each handling sequences independently. This combination allows LLMs to be highly adaptable and perform diverse tasks effectively.\n",
      "</think>\n",
      "\n",
      "Large Language Models (LLMs), such as those developed by models like GPT-3, operate through a series of interconnected layers that transform and handle sequential data with the help of attention mechanisms. These components constitute its neural network architecture.\n",
      "\n",
      "1. **Neural Network Components**:\n",
      "   - The LLM's neural network is comprised of multiple specialized models, each designed to tackle specific tasks or subtasks. For example, some models focus on processing words related to sentence structure (role language), while others handle the translation between languages.\n",
      "   - These components process input by transforming it through layers that maintain hidden states. This allows them to extract meaningful patterns from data.\n",
      "\n",
      "2. **Attention Mechanisms**:\n",
      "   - Attention plays a crucial role in these models, helping them focus on relevant parts of the text or input when processing tasks like translating words or generating responses.\n",
      "   - This context-dependent selection ensures the model isn't rigid, adapting based on the needed input and output structure.\n",
      "\n",
      "3. **Transformers**:\n",
      "   - Each LLM component employs a transformer architecture. Transformers do not process data in strict sequential layers but instead analyze sequences by treating them as flexible subtasks or models in parallel.\n",
      "   - This reduces dependency between units, enabling models to adapt without rigid sequencing.\n",
      "\n",
      "In essence, the LLM's neural network is structured with several focused components using attention and transformers, allowing it to handle diverse tasks through flexibility and adaptability.\n"
     ]
    }
   ],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
